# PrismIA - AI-Assisted Recruitment Methodology

> An experimental framework exploring how AI can reduce bias and improve efficiency in talent acquisition workflows.

## About This Project

As a junior recruiter learning AI-powered hiring tools, I designed this methodology to understand how large language models (GPT-4, Claude, Qwen, DeepSeek) could systematically assist with recruitment decisions while minimizing unconscious bias.

**What this is:** A collection of 8 system prompts implementing a structured, evidence-based approach to candidate evaluation.

**What this isn't:** Production software or a proven methodology. This is a learning project developed through personal research and experimentation.

## Motivation

After working with AI models since 2022 and completing my first placement (pro bono, 3 hours from sourcing to recommendation), I wanted to formalize the process I used. Traditional recruiting often relies on gut feelings - I wanted to explore whether AI could help make more objective, data-driven decisions.

## Key Features

- **100-Point Scoring System**: Transparent evaluation rubrics (30% behavioral, 70% technical)
- **Dual Bias Checkpoints**: Built-in review stages that challenge subjective reasoning
- **8-Step Workflow**: From semantic CV analysis through final selection
- **Multi-Modal Assessment**: Text, behavioral, and technical evaluation protocols
- **Asynchronous Framework**: Designed for remote-first hiring workflows

## System Prompts

| Prompt | Purpose | Key Feature |
|--------|---------|-------------|
| `RecruiterRP.md` | Interview simulation | Realistic role-play with dynamic scoring |
| `CandidateRP.md` | Candidate perspective scenarios | Empathy-building for recruiters |
| `CVAnalysis.md` | Resume parsing | Semantic NLP analysis beyond keywords |
| `Communication.md` | Candidate engagement | Automated personalized messaging |
| `Outreach-PreQualifScreening.md` | Initial contact + screening | Knockout criteria filtering |
| `Assessment.md` | Technical/behavioral testing | Comprehensive evaluation framework |
| `InterviewFeedback.md` | Post-interview analysis | Structured feedback collection |
| `IntreviewDebate.md` | Discussion framework | Collaborative decision-making |

## How to Use

These prompts are designed for use with AI assistants (GPT-4, Claude 3.5 Sonnet, etc.):

1. Choose the appropriate prompt for your recruitment stage
2. Copy the system prompt into your AI assistant
3. Follow the structured workflow outlined in the prompt
4. Document scores and decisions for bias review

**Note:** These are experimental prompts I developed while learning. They haven't been tested in production environments.

## Technologies Referenced

- **LLMs (by the order I prefer**: Claude 4.5 Sonnet 32k, GLM 4.6, GPT 5 High
- **Methodology**: Universal Asynchronous Screening Framework
- **Evaluation**: 100-point transparent scoring rubrics

## Limitations

- **No production testing**: Developed through personal research, not validated in real hiring pipelines
- **Junior perspective**: Created by someone learning AI recruiting, not a senior practitioner
- **Theoretical framework**: Focuses on methodology design rather than implementation

## Learnings

Through building this project, I gained understanding of:

- Structured prompt engineering for complex workflows
- Bias mitigation strategies in AI-assisted decision-making
- Balance between AI automation and human judgment
- Importance of transparent evaluation criteria

## Future Improvements

- [ ] Test prompts with real candidate data (anonymized)
- [ ] Add quantitative validation metrics
- [ ] Develop integration guides for ATS platforms
- [ ] Create simplified versions for different seniority levels
- [ ] Add multilingual support (French/English)

## Contributing

Feedback and suggestions are welcome! As someone early in their recruiting career, I'm open to learning from experienced practitioners.

If you see areas for improvement:
- Open an issue describing the problem
- Suggest methodology refinements
- Share your experience if you test these prompts

## Context

This project represents ~40 hours of iterative research and development in October 2025. It synthesizes concepts from:

- AI model testing
- 21+ precises AI-generated candidates profile analyses during methodology validation
- Study of modern talent acquisition frameworks

## Author

**Gabriel Jossic**  
Junior AI-Powered Recruiter | Rimouski, QC  
[LinkedIn](https://www.linkedin.com/in/gabriel-jossic) | gabriel@jossic.net

---

*Built with curiosity about how AI can make hiring more fair and efficient.*
